{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarking using SemHash on NLU Evaluation Corpora\n",
    "\n",
    "This notebook benchmarks the results on the 3 NLU Evaluation Corpora:\n",
    "1. Ask Ubuntu Corpus\n",
    "2. Chatbot Corpus\n",
    "3. Application Corpus\n",
    "\n",
    "\n",
    "More information about the dataset is available here: \n",
    "\n",
    "https://github.com/sebischair/NLU-Evaluation-Corpora\n",
    "\n",
    "\n",
    "* Semantic Hashing is used as a featurizer. The idea is taken from the paper:\n",
    "\n",
    "https://www.microsoft.com/en-us/research/publication/learning-deep-structured-semantic-models-for-web-search-using-clickthrough-data/\n",
    "\n",
    "* Benchmarks are performed on the same train and test datasets used by the other benchmarks performed in the past. One important paper that benchmarks the datasets mentioned above on some important platforms (Dialogflow, Luis, Watson and RASA) is : \n",
    "\n",
    "http://workshop.colips.org/wochat/@sigdial2017/documents/SIGDIAL22.pdf\n",
    "\n",
    "* Furthermore, Botfuel made another benchmarks with more platforms (Recast, Snips and their own) and results can be found here: \n",
    "\n",
    "https://github.com/Botfuel/benchmark-nlp-2018\n",
    "\n",
    "* The blogpost about the benchmarks is available at : \n",
    "\n",
    "https://medium.com/botfuel/benchmarking-intent-classification-services-june-2018-eb8684a1e55f\n",
    "\n",
    "* To be very fair on our benchmarks and results, we used the same train and test set used by the other benchmarks and no cross validation or stratified splits were used. The test data was not used in any way to improve the results. The data\n",
    "https://github.com/kumar-shridhar/HackathonLulea/tree/master/datasets/test-train-split\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import json\n",
    "import csv\n",
    "import spacy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy english dataset needs to be present. It can be downloaded using the following command:\n",
    "\n",
    "python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "intent_dict = {\"Make Update\":0, \"Setup Printer\":1, \"Shutdown Computer\":2, \"Software Recommendation\":3, \"None\":4}\n",
    "\n",
    "def read_CSV_datafile(filename):    \n",
    "    X = []\n",
    "    y = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            X.append(row[0])\n",
    "            y.append(intent_dict[row[1]])\n",
    "    return X,y\n",
    "        \n",
    "\n",
    "X_train_raw, y_train_raw = read_CSV_datafile(filename = \"datasets/KL/Ubuntu/train_new.csv\")\n",
    "X_test_raw, y_test_raw = read_CSV_datafile(filename = \"datasets/KL/Ubuntu/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_data: \n",
      " ['Upgrade 12.04 to 12.10 using startup disk', \"How to Upgrade from 11.10 to 12.04 when you've got a problem?\", 'Update 11.04 to 12.04 with LiveCD', 'How to upgrade Ubuntu 9.10 to 12.10 via terminal?'] \n",
      "\n",
      "\n",
      "y: \n",
      " [0, 0, 0, 0] \n",
      "\n",
      "\n",
      "Size of Corpus: 61\n",
      "Size of y: 61\n"
     ]
    }
   ],
   "source": [
    "print(\"corpus_data: \\n\",X_train_raw[-5:-1], \"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"y: \\n\", y_train_raw[-5:-1], \"\\n\\n\")\n",
    "\n",
    "print(\"Size of Corpus: {}\\nSize of y: {}\".format(len(X_train_raw), len(y_train_raw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    \"\"\"\n",
    "    Returns a list of strings containing each token in `sentence`\n",
    "    \"\"\"\n",
    "    #return [i for i in re.split(r\"([-.\\\"',:? !\\$#@~()*&\\^%;\\[\\]/\\\\\\+<>\\n=])\",\n",
    "    #                            doc) if i != '' and i != ' ' and i != '\\n']\n",
    "    tokens = []\n",
    "    doc = nlp.tokenizer(doc)\n",
    "    for token in doc:\n",
    "        tokens.append(token.text)\n",
    "    return tokens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(doc):\n",
    "    clean_tokens = []\n",
    "    doc = nlp(doc)\n",
    "    for token in doc:\n",
    "        if not token.is_stop:\n",
    "            clean_tokens.append(token.lemma_)\n",
    "    return \" \".join(clean_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])\n",
    "\n",
    "def semhash_tokenizer(text):\n",
    "    tokens = text.split(\" \")\n",
    "    final_tokens = []\n",
    "    for unhashed_token in tokens:\n",
    "        hashed_token = \"#{}#\".format(unhashed_token)\n",
    "        final_tokens += [''.join(gram)\n",
    "                         for gram in list(find_ngrams(list(hashed_token), 3))]\n",
    "    return final_tokens\n",
    "\n",
    "def semhash_corpus(corpus):\n",
    "    new_corpus = []\n",
    "    for sentence in corpus:\n",
    "        sentence = preprocess(sentence)\n",
    "        tokens = semhash_tokenizer(sentence)\n",
    "        new_corpus.append(\" \".join(map(str,tokens)))\n",
    "    return new_corpus\n",
    "\n",
    "X_train_raw = semhash_corpus(X_train_raw)\n",
    "X_test_raw = semhash_corpus(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#ho how ow# #re rec eco cor ord rd# #sc scr cre ree een en# #?#',\n",
       " '#ho how ow# #re rec eco cor ord rd# #di dis isp spl pla lay ay# #?#',\n",
       " '#ho how ow# #re rec eco cor ord rd# #mo mon oni nit ito tor or# #?#',\n",
       " '#an any ny# #co com omm mma man and nd# #li lin ine ne# #ca cal alc lcu cul ula lat ato tor or# #ub ubu bun unt ntu tu# #?#',\n",
       " '#ex ext xtr tra rac act ct# #em emb mbe bed ed# #im ima mag age ge# #pd pdf df#']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vectorizer(corpus, preprocessor=None, tokenizer=None):\n",
    "    vectorizer = CountVectorizer(ngram_range=(2,4),analyzer='char')\n",
    "    vectorizer.fit(corpus)\n",
    "    return vectorizer, vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, X_train, y_train, X_test, y_test, target_names,\n",
    "              print_report=True, feature_names=None, print_top10=False,\n",
    "              print_cm=True):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    #print(\"Accuracy: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate([\"Make Update\", \"Setup Printer\", \"Shutdown Computer\",\"Software Recommendation\", \"None\"]):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join([feature_names[i] for i in top10]))))\n",
    "        print()\n",
    "\n",
    "    if print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    # make some plots\n",
    "    indices = np.arange(len(results))\n",
    "\n",
    "    results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "    clf_names, score, training_time, test_time = results\n",
    "    training_time = np.array(training_time) / np.max(training_time)\n",
    "    test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Score\")\n",
    "    plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "    plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "             color='c')\n",
    "    plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "    plt.yticks(())\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplots_adjust(left=.25)\n",
    "    plt.subplots_adjust(top=.95)\n",
    "    plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "    for i, c in zip(indices, clf_names):\n",
    "        plt.text(-.3, i, c)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_for_training():\n",
    "    vectorizer, feature_names = get_vectorizer(X_train_raw, preprocessor=preprocess, tokenizer=tokenize)\n",
    "    \n",
    "    X_train = vectorizer.transform(X_train_raw).toarray()\n",
    "    X_test = vectorizer.transform(X_test_raw).toarray()\n",
    "            \n",
    "    return X_train, y_train_raw, X_test, y_test_raw, feature_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Split 0\n",
      "Train Size: 61\n",
      "Test Size: 109\n",
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n",
      "train time: 0.012s\n",
      "test time:  0.003s\n",
      "accuracy:   0.899\n",
      "dimensionality: 3858\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.95      0.97      0.96        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.94      0.78      0.85        40\n",
      "                   None       0.40      0.80      0.53         5\n",
      "\n",
      "            avg / total       0.92      0.90      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  0  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  1  0 31  6]\n",
      " [ 0  0  0  1  4]]\n",
      "\n",
      "================================================================================\n",
      "gridsearchknn\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shri/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 2.252s\n",
      "test time:  0.044s\n",
      "accuracy:   0.743\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.85      0.95      0.90        37\n",
      "          Setup Printer       1.00      0.62      0.76        13\n",
      "      Shutdown Computer       0.92      0.86      0.89        14\n",
      "Software Recommendation       0.96      0.55      0.70        40\n",
      "                   None       0.17      0.80      0.28         5\n",
      "\n",
      "            avg / total       0.89      0.74      0.78       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  0  1  0  1]\n",
      " [ 3  8  0  0  2]\n",
      " [ 0  0 12  0  2]\n",
      " [ 3  0  0 22 15]\n",
      " [ 0  0  0  1  4]]\n",
      "\n",
      "================================================================================\n",
      "gridsearchmlp\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'hidden_layer_sizes': [(100, 50), (300, 100, 50), (200, 100), (500, 300, 100, 50)]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i_s, split in enumerate(range(1)):\n",
    "    print(\"Evaluating Split {}\".format(i_s))\n",
    "    X_train, y_train, X_test, y_test, feature_names = data_for_training()\n",
    "    target_names = [\"Make Update\", \"Setup Printer\", \"Shutdown Computer\",\"Software Recommendation\", \"None\"]\n",
    "    print(\"Train Size: {}\\nTest Size: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "    results = []\n",
    "    #alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "    parameters_mlp={'hidden_layer_sizes':[(100,50),(300,100,50),(200,100),(500,300,100,50)]}\n",
    "    parameters_RF={ \"n_estimators\" : [50,60,70],\n",
    "           \"min_samples_leaf\" : [1, 2]}\n",
    "    k_range = list(range(1, 11))\n",
    "    parameters_knn = {'n_neighbors':k_range}\n",
    "    knn=KNeighborsClassifier(n_neighbors=5)\n",
    "    for clf, name in [  \n",
    "            (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "            (GridSearchCV(knn,parameters_knn, cv=10),\"gridsearchknn\"),\n",
    "            #(Perceptron(n_iter=50), \"Perceptron\"),\n",
    "            (GridSearchCV(MLPClassifier(activation='tanh'),parameters_mlp, cv=10),\"gridsearchmlp\"),\n",
    "           # (MLPClassifier(hidden_layer_sizes=(100, 50), activation=\"logistic\", max_iter=300), \"MLP\"),\n",
    "            #(MLPClassifier(hidden_layer_sizes=(300, 100, 50), activation=\"logistic\", max_iter=500), \"MLP\"),\n",
    "           # (MLPClassifier(hidden_layer_sizes=(300, 100, 50), activation=\"tanh\", max_iter=500), \"MLP\"),\n",
    "            (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "           # (KNeighborsClassifier(n_neighbors=1), \"kNN\"),\n",
    "           # (KNeighborsClassifier(n_neighbors=3), \"kNN\"),\n",
    "           # (KNeighborsClassifier(n_neighbors=5), \"kNN\"),\n",
    "            #(KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "            (GridSearchCV(RandomForestClassifier(n_estimators=10),parameters_RF, cv=10),\"gridsearchRF\")\n",
    "            #(RandomForestClassifier(n_estimators=10), \"Random forest\"),\n",
    "            #(RandomForestClassifier(n_estimators=50), \"Random forest\")\n",
    "    ]:\n",
    "           \n",
    "        print('=' * 80)\n",
    "        print(name)\n",
    "        results.append(benchmark(clf, X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "       # print('parameters')\n",
    "       # print(clf.grid_scores_[0])\n",
    "        #print('CV Validation Score')\n",
    "       # print(clf.grid_scores_[0].cv_validation_scores)\n",
    "       # print('Mean Validation Score')\n",
    "       # print(clf.grid_scores_[0].mean_validation_score)\n",
    "       # grid_mean_scores = [result.mean_validation_score for result in clf.grid_scores_]\n",
    "       # print(grid_mean_scores)\n",
    "       # plt.plot(k_range, grid_mean_scores)\n",
    "       # plt.xlabel('Value of K for KNN')\n",
    "       # plt.ylabel('Cross-Validated Accuracy')\n",
    "\n",
    "    #parameters_Linearsvc = [{'C': [1, 10], 'gamma': [0.1,1.0]}]\n",
    "    for penalty in [\"l2\", \"l1\"]:\n",
    "        print('=' * 80)\n",
    "        print(\"%s penalty\" % penalty.upper())\n",
    "        # Train Liblinear model\n",
    "        #grid=(GridSearchCV(LinearSVC,parameters_Linearsvc, cv=10),\"gridsearchSVC\")\n",
    "        #results.append(benchmark(LinearSVC(penalty=penalty), X_train, y_train, X_test, y_test, target_names,\n",
    "                                # feature_names=feature_names))\n",
    "        results.append(benchmark(LinearSVC(penalty=penalty, dual=False,tol=1e-3),\n",
    "                                 X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "\n",
    "        # Train SGD model\n",
    "        results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                               penalty=penalty),\n",
    "                                 X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "\n",
    "    # Train SGD with Elastic Net penalty\n",
    "    print('=' * 80)\n",
    "    print(\"Elastic-Net penalty\")\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=\"elasticnet\"),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "\n",
    "    # Train NearestCentroid without threshold\n",
    "    print('=' * 80)\n",
    "    print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "    results.append(benchmark(NearestCentroid(),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "\n",
    "    # Train sparse Naive Bayes classifiers\n",
    "    print('=' * 80)\n",
    "    print(\"Naive Bayes\")\n",
    "    results.append(benchmark(MultinomialNB(alpha=.01),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    results.append(benchmark(BernoulliNB(alpha=.01),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "\n",
    "    print('=' * 80)\n",
    "    print(\"LinearSVC with L1-based feature selection\")\n",
    "    # The smaller C, the stronger the regularization.\n",
    "    # The more regularization, the more sparsity.\n",
    "    \n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "    results.append(benchmark(Pipeline([\n",
    "                                  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                                                  tol=1e-3))),\n",
    "                                  ('classification', LinearSVC(penalty=\"l2\"))]),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "   # print(grid.grid_scores_)\n",
    "   #KMeans clustering algorithm \n",
    "    print('=' * 80)\n",
    "    print(\"KMeans\")\n",
    "    results.append(benchmark(KMeans(n_clusters=2, init='k-means++', max_iter=300,\n",
    "                verbose=0, random_state=0, tol=1e-4),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    \n",
    "   \n",
    "    \n",
    "    print('=' * 80)\n",
    "    print(\"LogisticRegression\")\n",
    "    #kfold = model_selection.KFold(n_splits=2, random_state=0)\n",
    "    #model = LinearDiscriminantAnalysis()\n",
    "    results.append(benchmark(LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    \n",
    "    plot_results(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
