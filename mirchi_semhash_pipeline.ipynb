{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/insideout/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/insideout/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import spacy\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from os import *\n",
    "#import keras\n",
    "#import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from time import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/insideout/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/insideout/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#infra_path = os.path.join(\"data\", \"error_classification\", \"tocheck.txt\")\n",
    "#infra_path = os.path.join(\"data\", \"error_classification\", \"sample.txt\")\n",
    "# infra_path = os.path.join(\"data\", \"error_classification\", \"InfraRELATEDCHECK.txt\")\n",
    "# user_path = os.path.join(\"data\", \"error_classification\", \"USERRELATEDCHECK1.txt\")\n",
    "import json\n",
    "import csv\n",
    "intent_dict = {\"Make Update\":0, \"Setup Printer\":1, \"Shutdown Computer\":2, \"Software Recommendation\":3, \"None\":4}\n",
    "\n",
    "#intent_dict = {\"Make Update\":0, \"Setup Printer\":1, \"Shutdown Computer\":2, \"Software Recommendation\":3, \"None\":4}\n",
    "\n",
    "def read_CSV_datafile(filename):    \n",
    "    X = []\n",
    "    y = []\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            X.append(row[0])\n",
    "            y.append(intent_dict[row[1]])\n",
    "    return X,y\n",
    "        \n",
    "ubuntu_data_path = os.path.join(\"datasets\",\"NLU-Evaluation-Corpora\",\"AskUbuntuCorpus.json\")\n",
    "\n",
    "with open(ubuntu_data_path) as f:\n",
    "    ubuntu_data = json.load(f)\n",
    "    \n",
    "sentences = ubuntu_data[\"sentences\"]\n",
    "\n",
    "corpus = []\n",
    "y = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    corpus.append(sentence[\"text\"])\n",
    "    y.append(intent_dict[sentence[\"intent\"]])\n",
    "# infra_data = [l.strip() for l in codecs.open(infra_path, \"r\", \"utf-8\")]\n",
    "# user_data = [l.strip() for l in codecs.open(user_path, \"r\", \"utf-8\")]\n",
    "\n",
    "#infra_data=codecs.open(infra_path,\"r\",\"utf-8\")\n",
    "\n",
    "#print len(serialize2)\n",
    "\n",
    "X_train_raw, y_train_raw = read_CSV_datafile(filename = \"datasets/KL/Ubuntu/train_new.csv\")\n",
    "X_test_raw, y_test_raw = read_CSV_datafile(filename = \"datasets/KL/Ubuntu/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus_data: \n",
      " ['Are there any Keyboard Shortcuts to Shutdown?', 'Shutdown after a certain time', 'Shutdown problem in Ubuntu 16.04', 'How do I fix a shutdown problem?'] \n",
      "\n",
      "\n",
      "y: \n",
      " [2, 2, 2, 2] \n",
      "\n",
      "\n",
      "Size of Corpus: 162\n",
      "Size of y: 162\n"
     ]
    }
   ],
   "source": [
    "print(\"corpus_data: \\n\",corpus[-5:-1], \"\\n\\n\")\n",
    "\n",
    "\n",
    "print(\"y: \\n\", y[-5:-1], \"\\n\\n\")\n",
    "\n",
    "print(\"Size of Corpus: {}\\nSize of y: {}\".format(len(corpus), len(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(X, y, n_splits=5, test_size=0.66):\n",
    "    skf = StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=0)\n",
    "    skf.get_n_splits(X, y)\n",
    "    splits = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        print(\"TRAIN:\", train_index, \"\\n\\n\", \"TEST:\", test_index, \"\\n\\n\")\n",
    "        X_train, X_test = [X[i] for i in train_index], [X[i] for i in test_index]\n",
    "        y_train, y_test = [y[i] for i in train_index], [y[i] for i in test_index]\n",
    "        splits.append({\"train\": {\"X\": X_train, \"y\": y_train},\n",
    "                       \"test\": {\"X\": X_test, \"y\": y_test}})\n",
    "    return splits\n",
    "#print X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc):\n",
    "    \"\"\"\n",
    "    Returns a list of strings containing each token in `sentence`\n",
    "    \"\"\"\n",
    "    #return [i for i in re.split(r\"([-.\\\"',:? !\\$#@~()*&\\^%;\\[\\]/\\\\\\+<>\\n=])\",\n",
    "    #                            doc) if i != '' and i != ' ' and i != '\\n']\n",
    "    tokens = []\n",
    "    doc = nlp.tokenizer(doc)\n",
    "    for token in doc:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #      token.shape_, token.is_alpha, token.is_stop)\n",
    "        #if not token.is_stop:\n",
    "        #    clean_tokens.append(token.lemma_)\n",
    "        tokens.append(token.text)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def preprocess(doc):\n",
    "    clean_tokens = []\n",
    "    doc = nlp(doc)\n",
    "    for token in doc:\n",
    "        #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "        #      token.shape_, token.is_alpha, token.is_stop)\n",
    "        if not token.is_stop:\n",
    "            clean_tokens.append(token.lemma_)\n",
    "        #clean_tokens.append(token.lemma_)\n",
    "    return \" \".join(clean_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SemHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ngrams(input_list, n):\n",
    "    return zip(*[input_list[i:] for i in range(n)])\n",
    "\n",
    "def semhash_tokenizer(text):\n",
    "    tokens = text.split(\" \")\n",
    "    final_tokens = []\n",
    "    for unhashed_token in tokens:\n",
    "        hashed_token = \"#{}#\".format(unhashed_token)\n",
    "        final_tokens += [''.join(gram)\n",
    "                         for gram in list(find_ngrams(list(hashed_token), 3))]\n",
    "    return final_tokens\n",
    "\n",
    "def semhash_corpus(corpus):\n",
    "    new_corpus = []\n",
    "    for sentence in corpus:\n",
    "        sentence = preprocess(sentence)\n",
    "        tokens = semhash_tokenizer(sentence)\n",
    "        new_corpus.append(\" \".join(map(str,tokens)))\n",
    "    return new_corpus\n",
    "\n",
    "corpus = semhash_corpus(corpus)\n",
    "\n",
    "X_train_raw = semhash_corpus(X_train_raw)\n",
    "X_test_raw = semhash_corpus(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#wh wha hat at# #so sof oft ftw twa war are re# #-P -PR PRO RON ON- N-# #us use se# #vi vie iew ew# #ep epu pub ub# #do doc ocu cum ume men ent nt# #?#',\n",
       " '#wh whi hic ich ch# #pd pdf df# #vi vie iew ewe wer er# #re rec eco com omm mme men end nd# #?#',\n",
       " '#wh wha hat at# #id ide de# #av ava vai ail ila lab abl ble le# #ub ubu bun unt ntu tu# #?#',\n",
       " '#wh wha hat at# #be be# #go goo ood od# #mi min ind nd# #ma map app ppi pin ing ng# #so sof oft ftw twa war are re# #?#',\n",
       " '#so sof oft ftw twa war are re# #re rea ead ad# #qr qr# #co cod ode de# #?#']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-PRON- fly kite man blue shirt try steal wallet\n"
     ]
    }
   ],
   "source": [
    "clean_doc = preprocess(\"I was flying a kite when the man in the blue shirt tried to steal my wallet\")\n",
    "print(clean_doc)\n",
    "#type(clean_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-PRON-', 'fly', 'kite', 'man', 'blue', 'shirt', 'try', 'steal', 'wallet']\n"
     ]
    }
   ],
   "source": [
    "tokens_from_clean_text = tokenize(clean_doc)\n",
    "print(tokens_from_clean_text)\n",
    "#type(tokens_from_clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorizer(corpus, preprocessor=None, tokenizer=None):\n",
    "    vectorizer = CountVectorizer(ngram_range=(2,4),analyzer='char')\n",
    "    vectorizer.fit(corpus)\n",
    "    return vectorizer, vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/insideout/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, X_train, y_train, X_test, y_test, target_names,\n",
    "              print_report=True, feature_names=None, print_top10=False,\n",
    "              print_cm=True):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    #print(\"Accuracy: %0.3f (+/- %0.3f)\" % (score.mean(), score.std() * 2))\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate([\"Make Update\", \"Setup Printer\", \"Shutdown Computer\",\"Software Recommendation\", \"None\"]):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join([feature_names[i] for i in top10]))))\n",
    "        print()\n",
    "\n",
    "    if print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "    #avg=cross_val_score(clf,corpus,y,cv=5)\n",
    "#print avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    # make some plots\n",
    "    indices = np.arange(len(results))\n",
    "\n",
    "    results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "    clf_names, score, training_time, test_time = results\n",
    "    training_time = np.array(training_time) / np.max(training_time)\n",
    "    test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Score\")\n",
    "    plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "    plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "             color='c')\n",
    "    plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "    plt.yticks(())\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplots_adjust(left=.25)\n",
    "    plt.subplots_adjust(top=.95)\n",
    "    plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "    for i, c in zip(indices, clf_names):\n",
    "        plt.text(-.3, i, c)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_andy_from_split():\n",
    "    # train_corpus, y_train = split[\"train\"][\"X\"], split[\"train\"][\"y\"]\n",
    "    # test_corpus, y_test = split[\"test\"][\"X\"], split[\"test\"][\"y\"]\n",
    "    vectorizer, feature_names = get_vectorizer(X_train_raw, preprocessor=preprocess, tokenizer=tokenize)\n",
    "    \n",
    "    X_train = vectorizer.transform(X_train_raw).toarray()\n",
    "    X_test = vectorizer.transform(X_test_raw).toarray()\n",
    "    \n",
    "    #for i,label in enumerate(y_train):\n",
    "     #   if label == 4:\n",
    "      #      y_train = np.append(y_train,[4], axis=0)\n",
    "       #     X_train = np.append(X_train,X_train[i], axis=0)\n",
    "            \n",
    "    return X_train, y_train_raw, X_test, y_test_raw, feature_names\n",
    "#print feature_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [123 151  27 143  79 103  62 119  81 108   8  25  61 154 125  83 137 116\n",
      " 133  80  17  85   4  49  33 134  38 138 130  16 129 161   7  19 105  84\n",
      "  87  70 152  52 109  93 150   1 160 127  74 146  32 117   6  12  44  54\n",
      "  82] \n",
      "\n",
      " TEST: [149 114  43 111  46  57  26 148 113  28  13   0  21 145  90  76 115  22\n",
      "  40  39  58 112  94  42 124  65 110  23 147  89 156 107  88 142 141 118\n",
      "  11   9  60  24  37  14  63  66  64  51  41  36 140  78 101  98  72  47\n",
      "  35 153 102 128 104  75 131  59 106  20 132  10  97 144 159   3  91   5\n",
      " 126  18  55  96  15  95  50 136  56 157  48 158  73  34 120  77  53 100\n",
      " 155  69  68  86 122  99 139   2  45  30 121 135  67  29  92  71  31] \n",
      "\n",
      "\n",
      "TRAIN: [  6 102  51 151 123  56 104  77  70 100 149   2  73  94 113 147  60  97\n",
      "  26 111  11  95  37  58  12 161  92  86  18  14  52 121  89  34 144  41\n",
      " 127 134 132  96  83  47  88   8  63  55 131 159  38 118  40   5  31 135\n",
      "  66] \n",
      "\n",
      " TEST: [128 105  87  13 138  98  27  53 148 155   0 125  20  33 119   1  23 139\n",
      "  82  39   7  28  67  68 143 154  79  64 107  44 141 116 133  90  62   3\n",
      "  91 160  22  29 112 142  84  49 124  85 103 150  17  69 108 137  50 129\n",
      " 114   9 110  61   4  65 115  72  81 122 156 126  99  71 140 136 120  32\n",
      "  57  78  80 157  45  46 158 153  30  21  76  74  43  10  24 117 146 109\n",
      " 152 101  19  16  93  59  15 130  75  25 145  35  54 106  36  42  48] \n",
      "\n",
      "\n",
      "TRAIN: [ 62  17  67   7  71 117  95 128  13  21  44  14  43  52   4 159  89 145\n",
      " 121 124  86  22 106 104  72  29   1  50  41  15 123  74  47   9 109   5\n",
      "  36 135 116  12 154  48 120 158  97 129 147  73  82  91  64  16  60  66\n",
      " 144] \n",
      "\n",
      " TEST: [ 70  42  34 125 149 148 101  76 151 141  10   2  38   8  57  81 136 114\n",
      " 108 160  26  98  55 122  83 131  78  63  88  11  92  80  23 139 143 126\n",
      "   6 161  61  45 107  18 150 155 142 133  32  39 130 138 132 134  84 115\n",
      " 105 118  20  27  25 140  96  87 102  30  75  51 119  69  53 113 153  68\n",
      " 127  46  28 100 156 103  94  24  90  49  56   3 111  59  85  65  58 137\n",
      "  93 112  99   0  19 110  54 157  79  40  35 152  37  33 146  31  77] \n",
      "\n",
      "\n",
      "TRAIN: [ 91 119 113 139  23  65 100 109 146 157  37 128  19  45  83  67  31 133\n",
      "   5  32   6  25  63 158  96  20 125 138 115  22  78 118   4  36 161  73\n",
      "  48  34  77 130  13 101 160  57  81   2  50 152 106  84 103  89  93  82\n",
      "  30] \n",
      "\n",
      " TEST: [104 102 143 141 122   9 136 151 147   7  40  26  79  88  90  56 121 149\n",
      "  28   1 159  76  15  39 120   8 142  62  51 116  16 140 148  75  98 129\n",
      "  85  46  69 111  38  54 135 155  72 153  41  14 156  61  12  71  99  94\n",
      "  60 134  92 145 126  47  42 154  33  11  35  43  74  24  21 144  18  10\n",
      "  70 112  29  87   0 110  58  49  53 150  68 131  52  59  80  66 137  86\n",
      "  44  55 124  97 127 108   3 117  95 107 123 132  17 114  64  27 105] \n",
      "\n",
      "\n",
      "TRAIN: [ 80 128  60  72 106  45  86 129   8  37 134 144  36   9  14  11  34  84\n",
      "  10 158   3 109  58 116  21  12  43  55 142 117   4 124  91  62 149 159\n",
      "  90  75  77 154  99  56  22 150  96  59   0 126  82  66 140  28   6 104\n",
      "  29] \n",
      "\n",
      " TEST: [ 98 152 103  97  78  19 156  88  63  93  27 100 160  52 153  76  33 123\n",
      " 101  85  83  68   5 125 138  89  94  20  31 111  35  79  74  32  16 120\n",
      "  48 122 135 147  53 141 139 105 132  92 108 102 110  50  46  47   2 136\n",
      "  24  69  30 113  65  57  51  15 145 151  26 130 107  41 119 143  54 146\n",
      " 161  40 131  17  71   7 121  70 133  44  42  13 148 118  25 112  23 157\n",
      "  87 114  81  38   1  73 155  61 127  49 137  64  67  95  18 115  39] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "splits = stratified_split(corpus, y, n_splits=5, test_size=0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Split 0\n",
      "Train Size: 61\n",
      "Test Size: 109\n",
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n",
      "train time: 0.006s\n",
      "test time:  0.001s\n",
      "accuracy:   0.899\n",
      "dimensionality: 3858\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.95      0.97      0.96        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.94      0.78      0.85        40\n",
      "                   None       0.40      0.80      0.53         5\n",
      "\n",
      "            avg / total       0.92      0.90      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  0  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  1  0 31  6]\n",
      " [ 0  0  0  1  4]]\n",
      "\n",
      "================================================================================\n",
      "gridsearchknn\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/insideout/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 1.564s\n",
      "test time:  0.034s\n",
      "accuracy:   0.743\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.85      0.95      0.90        37\n",
      "          Setup Printer       1.00      0.62      0.76        13\n",
      "      Shutdown Computer       0.92      0.86      0.89        14\n",
      "Software Recommendation       0.96      0.55      0.70        40\n",
      "                   None       0.17      0.80      0.28         5\n",
      "\n",
      "            avg / total       0.89      0.74      0.78       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  0  1  0  1]\n",
      " [ 3  8  0  0  2]\n",
      " [ 0  0 12  0  2]\n",
      " [ 3  0  0 22 15]\n",
      " [ 0  0  0  1  4]]\n",
      "\n",
      "================================================================================\n",
      "gridsearchmlp\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=MLPClassifier(activation='tanh', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'hidden_layer_sizes': [(100, 50), (300, 100, 50), (200, 100), (500, 300, 100, 50)]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "train time: 25.942s\n",
      "test time:  0.002s\n",
      "accuracy:   0.899\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       1.00      1.00      1.00        13\n",
      "      Shutdown Computer       1.00      0.93      0.96        14\n",
      "Software Recommendation       0.90      0.88      0.89        40\n",
      "                   None       0.33      0.40      0.36         5\n",
      "\n",
      "            avg / total       0.90      0.90      0.90       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  0  0  1  1]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 13  0  1]\n",
      " [ 3  0  0 35  2]\n",
      " [ 0  0  0  3  2]]\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
      "              fit_intercept=True, loss='hinge', max_iter=50, n_iter=None,\n",
      "              n_jobs=1, random_state=None, shuffle=True, tol=None,\n",
      "              verbose=0, warm_start=False)\n",
      "train time: 0.118s\n",
      "test time:  0.001s\n",
      "accuracy:   0.908\n",
      "dimensionality: 3858\n",
      "density: 0.825350\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.95      0.95      0.95        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.90      0.88      0.89        40\n",
      "                   None       0.40      0.40      0.40         5\n",
      "\n",
      "            avg / total       0.91      0.91      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  0  0  1  1]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  1  0 35  2]\n",
      " [ 0  0  0  3  2]]\n",
      "\n",
      "================================================================================\n",
      "gridsearchRF\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "GridSearchCV(cv=10, error_score='raise',\n",
      "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid={'n_estimators': [50, 60, 70], 'min_samples_leaf': [1, 2]},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
      "       scoring=None, verbose=0)\n",
      "train time: 2.681s\n",
      "test time:  0.003s\n",
      "accuracy:   0.927\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.93      1.00      0.96        37\n",
      "          Setup Printer       1.00      0.92      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.92      0.88      0.90        40\n",
      "                   None       0.60      0.60      0.60         5\n",
      "\n",
      "            avg / total       0.93      0.93      0.93       109\n",
      "\n",
      "confusion matrix:\n",
      "[[37  0  0  0  0]\n",
      " [ 0 12  0  1  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  0  0 35  2]\n",
      " [ 0  0  0  2  3]]\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.008s\n",
      "test time:  0.000s\n",
      "accuracy:   0.908\n",
      "dimensionality: 3858\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.94      0.92      0.93        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.90      0.88      0.89        40\n",
      "                   None       0.50      0.60      0.55         5\n",
      "\n",
      "            avg / total       0.91      0.91      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[34  0  0  2  1]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  1  0 35  2]\n",
      " [ 0  0  0  2  3]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "train time: 0.059s\n",
      "test time:  0.000s\n",
      "accuracy:   0.899\n",
      "dimensionality: 3858\n",
      "density: 0.411560\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.93      1.00      0.96        37\n",
      "          Setup Printer       1.00      0.92      0.96        13\n",
      "      Shutdown Computer       0.88      1.00      0.93        14\n",
      "Software Recommendation       0.89      0.82      0.86        40\n",
      "                   None       0.50      0.40      0.44         5\n",
      "\n",
      "            avg / total       0.90      0.90      0.90       109\n",
      "\n",
      "confusion matrix:\n",
      "[[37  0  0  0  0]\n",
      " [ 0 12  0  1  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  0  2 33  2]\n",
      " [ 0  0  0  3  2]]\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.026s\n",
      "test time:  0.000s\n",
      "accuracy:   0.881\n",
      "dimensionality: 3858\n",
      "density: 0.005910\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.94      0.92      0.93        37\n",
      "          Setup Printer       0.81      1.00      0.90        13\n",
      "      Shutdown Computer       0.93      1.00      0.97        14\n",
      "Software Recommendation       0.89      0.82      0.86        40\n",
      "                   None       0.40      0.40      0.40         5\n",
      "\n",
      "            avg / total       0.88      0.88      0.88       109\n",
      "\n",
      "confusion matrix:\n",
      "[[34  2  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  1  1 33  3]\n",
      " [ 0  0  0  3  2]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='l1', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/insideout/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/insideout/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.169s\n",
      "test time:  0.000s\n",
      "accuracy:   0.917\n",
      "dimensionality: 3858\n",
      "density: 0.416278\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.88      1.00      0.94        37\n",
      "          Setup Printer       1.00      1.00      1.00        13\n",
      "      Shutdown Computer       0.93      1.00      0.97        14\n",
      "Software Recommendation       0.94      0.82      0.88        40\n",
      "                   None       0.75      0.60      0.67         5\n",
      "\n",
      "            avg / total       0.92      0.92      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[37  0  0  0  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 5  0  1 33  1]\n",
      " [ 0  0  0  2  3]]\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', max_iter=50, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False)\n",
      "train time: 0.165s\n",
      "test time:  0.000s\n",
      "accuracy:   0.945\n",
      "dimensionality: 3858\n",
      "density: 0.398756\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.97      0.95        37\n",
      "          Setup Printer       1.00      1.00      1.00        13\n",
      "      Shutdown Computer       0.93      1.00      0.97        14\n",
      "Software Recommendation       0.95      0.90      0.92        40\n",
      "                   None       1.00      0.80      0.89         5\n",
      "\n",
      "            avg / total       0.95      0.94      0.94       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  0  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  0  1 36  0]\n",
      " [ 0  0  0  1  4]]\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.001s\n",
      "test time:  0.001s\n",
      "accuracy:   0.881\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       0.77      0.77      0.77        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.92      0.88      0.90        40\n",
      "                   None       0.33      0.40      0.36         5\n",
      "\n",
      "            avg / total       0.89      0.88      0.88       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  1  0  0  1]\n",
      " [ 1 10  0  1  1]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  1  0 35  2]\n",
      " [ 0  1  0  2  2]]\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.001s\n",
      "test time:  0.001s\n",
      "accuracy:   0.899\n",
      "dimensionality: 3858\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       0.81      1.00      0.90        13\n",
      "      Shutdown Computer       0.88      1.00      0.93        14\n",
      "Software Recommendation       0.92      0.88      0.90        40\n",
      "                   None       1.00      0.20      0.33         5\n",
      "\n",
      "            avg / total       0.91      0.90      0.89       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  1  1  0  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  2  0 35  0]\n",
      " [ 0  0  1  3  1]]\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.002s\n",
      "accuracy:   0.917\n",
      "dimensionality: 3858\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.90      0.90      0.90        40\n",
      "                   None       0.67      0.40      0.50         5\n",
      "\n",
      "            avg / total       0.91      0.92      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  1  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  0  0 36  1]\n",
      " [ 0  0  0  3  2]]\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(memory=None,\n",
      "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        norm_order=1, prefit=...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/insideout/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n",
      "/home/insideout/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py:93: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(mask.dtype, np.int):\n",
      "/home/insideout/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.026s\n",
      "test time:  0.000s\n",
      "accuracy:   0.881\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.94      0.92      0.93        37\n",
      "          Setup Printer       1.00      1.00      1.00        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.89      0.80      0.84        40\n",
      "                   None       0.30      0.60      0.40         5\n",
      "\n",
      "            avg / total       0.91      0.88      0.89       109\n",
      "\n",
      "confusion matrix:\n",
      "[[34  0  0  2  1]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 2  0  0 32  6]\n",
      " [ 0  0  0  2  3]]\n",
      "\n",
      "================================================================================\n",
      "KMeans\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
      "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
      "    random_state=0, tol=0.0001, verbose=0)\n",
      "train time: 0.040s\n",
      "test time:  0.001s\n",
      "accuracy:   0.404\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.37      0.97      0.53        37\n",
      "          Setup Printer       0.73      0.62      0.67        13\n",
      "      Shutdown Computer       0.00      0.00      0.00        14\n",
      "Software Recommendation       0.00      0.00      0.00        40\n",
      "                   None       0.00      0.00      0.00         5\n",
      "\n",
      "            avg / total       0.21      0.40      0.26       109\n",
      "\n",
      "confusion matrix:\n",
      "[[36  1  0  0  0]\n",
      " [ 5  8  0  0  0]\n",
      " [14  0  0  0  0]\n",
      " [39  1  0  0  0]\n",
      " [ 4  1  0  0  0]]\n",
      "\n",
      "================================================================================\n",
      "LogisticRegression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "train time: 0.008s\n",
      "test time:  0.000s\n",
      "accuracy:   0.917\n",
      "dimensionality: 3858\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.92      0.88      0.90        40\n",
      "                   None       0.60      0.60      0.60         5\n",
      "\n",
      "            avg / total       0.92      0.92      0.92       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  0  0  1  1]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  1  0 35  1]\n",
      " [ 0  0  0  2  3]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3cCfx/eDZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3705c8e748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i_s, split in enumerate(range(1)):\n",
    "    print(\"Evaluating Split {}\".format(i_s))\n",
    "    X_train, y_train, X_test, y_test, feature_names = get_X_andy_from_split()\n",
    "    target_names = [\"Make Update\", \"Setup Printer\", \"Shutdown Computer\",\"Software Recommendation\", \"None\"]\n",
    "    print(\"Train Size: {}\\nTest Size: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "    results = []\n",
    "    #alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "    parameters_mlp={'hidden_layer_sizes':[(100,50),(300,100,50),(200,100),(500,300,100,50)]}\n",
    "    parameters_RF={ \"n_estimators\" : [50,60,70],\n",
    "           \"min_samples_leaf\" : [1, 2]}\n",
    "    k_range = list(range(1, 11))\n",
    "    parameters_knn = {'n_neighbors':k_range}\n",
    "    knn=KNeighborsClassifier(n_neighbors=5)\n",
    "    for clf, name in [  \n",
    "            (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "            (GridSearchCV(knn,parameters_knn, cv=10),\"gridsearchknn\"),\n",
    "            #(Perceptron(n_iter=50), \"Perceptron\"),\n",
    "            (GridSearchCV(MLPClassifier(activation='tanh'),parameters_mlp, cv=10),\"gridsearchmlp\"),\n",
    "           # (MLPClassifier(hidden_layer_sizes=(100, 50), activation=\"logistic\", max_iter=300), \"MLP\"),\n",
    "            #(MLPClassifier(hidden_layer_sizes=(300, 100, 50), activation=\"logistic\", max_iter=500), \"MLP\"),\n",
    "           # (MLPClassifier(hidden_layer_sizes=(300, 100, 50), activation=\"tanh\", max_iter=500), \"MLP\"),\n",
    "            (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "           # (KNeighborsClassifier(n_neighbors=1), \"kNN\"),\n",
    "           # (KNeighborsClassifier(n_neighbors=3), \"kNN\"),\n",
    "           # (KNeighborsClassifier(n_neighbors=5), \"kNN\"),\n",
    "            #(KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "            (GridSearchCV(RandomForestClassifier(n_estimators=10),parameters_RF, cv=10),\"gridsearchRF\")\n",
    "            #(RandomForestClassifier(n_estimators=10), \"Random forest\"),\n",
    "            #(RandomForestClassifier(n_estimators=50), \"Random forest\")\n",
    "    ]:\n",
    "           \n",
    "        print('=' * 80)\n",
    "        print(name)\n",
    "        results.append(benchmark(clf, X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "       # print('parameters')\n",
    "       # print(clf.grid_scores_[0])\n",
    "        #print('CV Validation Score')\n",
    "       # print(clf.grid_scores_[0].cv_validation_scores)\n",
    "       # print('Mean Validation Score')\n",
    "       # print(clf.grid_scores_[0].mean_validation_score)\n",
    "       # grid_mean_scores = [result.mean_validation_score for result in clf.grid_scores_]\n",
    "       # print(grid_mean_scores)\n",
    "       # plt.plot(k_range, grid_mean_scores)\n",
    "       # plt.xlabel('Value of K for KNN')\n",
    "       # plt.ylabel('Cross-Validated Accuracy')\n",
    "\n",
    "    #parameters_Linearsvc = [{'C': [1, 10], 'gamma': [0.1,1.0]}]\n",
    "    for penalty in [\"l2\", \"l1\"]:\n",
    "        print('=' * 80)\n",
    "        print(\"%s penalty\" % penalty.upper())\n",
    "        # Train Liblinear model\n",
    "        #grid=(GridSearchCV(LinearSVC,parameters_Linearsvc, cv=10),\"gridsearchSVC\")\n",
    "        #results.append(benchmark(LinearSVC(penalty=penalty), X_train, y_train, X_test, y_test, target_names,\n",
    "                                # feature_names=feature_names))\n",
    "        results.append(benchmark(LinearSVC(penalty=penalty, dual=False,tol=1e-3),\n",
    "                                 X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "\n",
    "        # Train SGD model\n",
    "        results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                               penalty=penalty),\n",
    "                                 X_train, y_train, X_test, y_test, target_names,\n",
    "                                 feature_names=feature_names))\n",
    "\n",
    "    # Train SGD with Elastic Net penalty\n",
    "    print('=' * 80)\n",
    "    print(\"Elastic-Net penalty\")\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=\"elasticnet\"),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "\n",
    "    # Train NearestCentroid without threshold\n",
    "    print('=' * 80)\n",
    "    print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "    results.append(benchmark(NearestCentroid(),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "\n",
    "    # Train sparse Naive Bayes classifiers\n",
    "    print('=' * 80)\n",
    "    print(\"Naive Bayes\")\n",
    "    results.append(benchmark(MultinomialNB(alpha=.01),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    results.append(benchmark(BernoulliNB(alpha=.01),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "\n",
    "    print('=' * 80)\n",
    "    print(\"LinearSVC with L1-based feature selection\")\n",
    "    # The smaller C, the stronger the regularization.\n",
    "    # The more regularization, the more sparsity.\n",
    "    \n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "    results.append(benchmark(Pipeline([\n",
    "                                  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                                                  tol=1e-3))),\n",
    "                                  ('classification', LinearSVC(penalty=\"l2\"))]),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "   # print(grid.grid_scores_)\n",
    "   #KMeans clustering algorithm \n",
    "    print('=' * 80)\n",
    "    print(\"KMeans\")\n",
    "    results.append(benchmark(KMeans(n_clusters=2, init='k-means++', max_iter=300,\n",
    "                verbose=0, random_state=0, tol=1e-4),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    \n",
    "   \n",
    "    \n",
    "    print('=' * 80)\n",
    "    print(\"LogisticRegression\")\n",
    "    #kfold = model_selection.KFold(n_splits=2, random_state=0)\n",
    "    #model = LinearDiscriminantAnalysis()\n",
    "    results.append(benchmark(LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
    "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    \n",
    "    plot_results(results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Split 0\n",
      "Train Size: 61\n",
      "Test Size: 109\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.002s\n",
      "test time:  0.003s\n",
      "accuracy:   0.917\n",
      "dimensionality: 3858\n",
      "density: 1.000000\n",
      "\n",
      "classification report:\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "            Make Update       0.92      0.95      0.93        37\n",
      "          Setup Printer       0.93      1.00      0.96        13\n",
      "      Shutdown Computer       1.00      1.00      1.00        14\n",
      "Software Recommendation       0.90      0.90      0.90        40\n",
      "                   None       0.67      0.40      0.50         5\n",
      "\n",
      "            avg / total       0.91      0.92      0.91       109\n",
      "\n",
      "confusion matrix:\n",
      "[[35  1  0  1  0]\n",
      " [ 0 13  0  0  0]\n",
      " [ 0  0 14  0  0]\n",
      " [ 3  0  0 36  1]\n",
      " [ 0  0  0  3  2]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuMAAAI1CAYAAAB8GvSWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIsYBAKDI/wNFYNVrGpFLRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3705c915f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "class_prior = [37/109, 13/109, 14/109, 40/109, 5/109]\n",
    "\n",
    "for i_s, split in enumerate(range(1)):\n",
    "    print(\"Evaluating Split {}\".format(i_s))\n",
    "    X_train, y_train, X_test, y_test, feature_names = get_X_andy_from_split()\n",
    "    target_names = [\"Make Update\", \"Setup Printer\", \"Shutdown Computer\",\"Software Recommendation\", \"None\"]\n",
    "    print(\"Train Size: {}\\nTest Size: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "    results = []\n",
    "    \n",
    "    # Train sparse Naive Bayes classifiers\n",
    "    print('=' * 80)\n",
    "    print(\"Naive Bayes\")\n",
    "    \n",
    "    results.append(benchmark(BernoulliNB(alpha=.01, fit_prior=True),\n",
    "                             X_train, y_train, X_test, y_test, target_names,\n",
    "                             feature_names=feature_names))\n",
    "    \n",
    "    plot_results(results)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
